import requests as re
from bs4 import BeautifulSoup as be
import string as st
from collections import Counter as cou

URL = 'https://knijky.ru/books/garri-potter-i-dary-smerti'
HEADERS = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36',
    'accept': '*/*'}


def get_html(url, params=None):
    r = re.get(url, headers=HEADERS, params=params)
    return r


def get_content(html):
    soup = be(html, 'html.parser')
    items = soup.find_all('p')
    bad_sims = st.punctuation + '—'
    words = ''
    for i in items:
        words += i.text
    res = ''
    for word in words:
        if word not in bad_sims:
            res += word.lower()
    return res


def get_pages_count(URL):
    html = get_html(URL)
    soup = be(html.text, 'html.parser')
    pagin = soup.find_all('a', class_='active')
    pag = [p.text for p in pagin]
    for i in range(len(pag)):
        if not pag[i].isdigit():
            del pag[i]
    return int(pag[-1])


def parse():
    html = get_html(URL)
    if html.status_code == 200:
        # get_content(html.text)
        words = ''
        pages_count = get_pages_count(URL)
        for page in range(1, 10 + 1):
            print(f'Парсинг страницы {page} из {pages_count}...')
            html = get_html(URL, params={'page': page})
            words += get_content(html.text)
        res = words.split()
        result = cou(res)
        print(len(result))
        for key in result:
            print(key, result[key])
    else:
        print('ERROR')

parse()
